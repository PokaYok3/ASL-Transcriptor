# Project Name

## Sign Language Transcription System

---

## Overview

The Sign Language Transcription System is an ongoing project aimed at developing a solution to transcribe sign language gestures into audio and text. The system utilizes cameras to capture sign language gestures and then processes the data through a graphical interface. The goal is to make sign language more accessible and enable seamless communication for individuals with hearing impairments.

**Note: This project is currently in development.**
Trainscription system implemented. 
The model trained not the best but identify the most of the signs.
Working with increased data collection and new training

---

## Features

- **Graphical User Interface (GUI):** A user-friendly interface to facilitate the entire sign language transcription process.
- **Data Capture Scripts:** Custom scripts for capturing training and testing data using cameras.
- **Transcription Scripts:** Algorithms for transcribing sign language gestures into audio and text.

---

## Prerequisites

Ensure you have the following dependencies installed before running the project:

- Python 3.11
- Tkinter
- OpenCV
- Mediapipe
- TensorFlow

## Usage
- Use the main.py to open the GUI and execute the process.
- At folder images/examplesignals  you will find examples of the different cases.

---

## Acknowledgments

We would like to express our gratitude to the [ASL Alphabet Dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet) provided by the Kaggle user [grassknoted]. This dataset has been instrumental in training and testing our sign language transcription system. The availability of high-quality data has significantly contributed to the accuracy and effectiveness of our project.

---



